{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Complete_code_jobcv using BERT and skills extraction by pyresparser.\n",
        "\n",
        "#Dropped becuase processing was taking 4 sec for each resume\n",
        "\n"
      ],
      "metadata": {
        "id": "uH0gg4Lk4PFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlLMIGkDSK5o",
        "outputId": "757da714-f8eb-41e3-e82a-ed3ed9e68064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q PyPDF2 sentence-transformers pandas openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4-NAevcVXMx",
        "outputId": "52e48bf3-9bb7-426c-891b-9aeb6171faae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NEMitEslAjm",
        "outputId": "d0f230fe-c415-4bb6-ef97-00bcfe2a5f7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "\n",
        "# Install SpaCy Dependencies\n",
        "os.system('python -m pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz')\n",
        "\n",
        "# Install nltk Dependencies\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViNr9jyRVNzh"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text by removing special characters, lowercasing, and trimming.\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters, digits, and extra spaces\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text content from a PDF file using PyPDF2.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text = \" \".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to extract relevant sections from resumes\n",
        "def extract_relevant_resume_sections(text):\n",
        "    \"\"\"\n",
        "    Extract relevant sections (skills, experience, education, and projects) from a resume.\n",
        "    Targets a variety of section headers.\n",
        "    \"\"\"\n",
        "    sections = {\"skills\": \"\", \"experience\": \"\", \"education\": \"\", \"projects\": \"\"}\n",
        "\n",
        "    # Skills Section\n",
        "    skills_match = re.search(r'(skills|technical skills|core competencies|areas of expertise)(.*?)(experience|education|projects|summary|$)', text, re.DOTALL)\n",
        "    if skills_match:\n",
        "        sections[\"skills\"] = skills_match.group(2).strip()\n",
        "\n",
        "    # Experience Section\n",
        "    experience_match = re.search(r'(experience|work history|employment history|professional experience|career summary)(.*?)(education|skills|projects|summary|$)', text, re.DOTALL)\n",
        "    if experience_match:\n",
        "        sections[\"experience\"] = experience_match.group(2).strip()\n",
        "\n",
        "    # Education Section\n",
        "    education_match = re.search(r'(education|academic background|qualifications|academic qualifications)(.*?)(experience|skills|projects|summary|$)', text, re.DOTALL)\n",
        "    if education_match:\n",
        "        sections[\"education\"] = education_match.group(2).strip()\n",
        "\n",
        "    # Projects Section (Optional)\n",
        "    projects_match = re.search(r'(projects|portfolio|notable work|key projects|case studies)(.*?)(experience|skills|education|summary|$)', text, re.DOTALL)\n",
        "    if projects_match:\n",
        "        sections[\"projects\"] = projects_match.group(2).strip()\n",
        "\n",
        "    # Combine all relevant sections\n",
        "    combined_text = \" \".join([sections[\"skills\"], sections[\"experience\"], sections[\"education\"], sections[\"projects\"]])\n",
        "    return preprocess_text(combined_text)\n",
        "\n",
        "# Function to extract relevant sections from a job description\n",
        "def extract_relevant_job_description_sections(text):\n",
        "    \"\"\"\n",
        "    Extract relevant sections (responsibilities, requirements, qualifications, skills) from a job description.\n",
        "    Targets a variety of section headers.\n",
        "    \"\"\"\n",
        "    # Responsibilities Section\n",
        "    responsibilities_match = re.search(r'(responsibilities|duties|role|tasks|job duties|job responsibilities)(.*?)(requirements|qualifications|skills|summary|desired skills|$)', text, re.DOTALL)\n",
        "    responsibilities = responsibilities_match.group(2).strip() if responsibilities_match else \"\"\n",
        "\n",
        "    # Requirements or Qualifications Section\n",
        "    requirements_match = re.search(r'(requirements|qualifications|skills|desired skills|eligibility criteria|job requirements)(.*?)(responsibilities|duties|summary|$)', text, re.DOTALL)\n",
        "    requirements = requirements_match.group(2).strip() if requirements_match else \"\"\n",
        "\n",
        "    # Skills Section (Optional)\n",
        "    skills_match = re.search(r'(skills|technical skills|core competencies|key qualifications|knowledge and abilities|preferred skills)(.*?)(responsibilities|requirements|summary|$)', text, re.DOTALL)\n",
        "    skills = skills_match.group(2).strip() if skills_match else \"\"\n",
        "\n",
        "    # Combine extracted sections\n",
        "    combined_text = \" \".join([responsibilities, requirements, skills])\n",
        "    return preprocess_text(combined_text)\n",
        "\n",
        "# Function to load and preprocess resumes\n",
        "def load_resumes(folder_path):\n",
        "    \"\"\"\n",
        "    Load all resumes from the specified folder, extract relevant sections, preprocess, and return as a list of tuples.\n",
        "    Each tuple contains (filename, preprocessed_text).\n",
        "    \"\"\"\n",
        "    resumes = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".pdf\"):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            raw_text = extract_text_from_pdf(file_path)\n",
        "            if raw_text:\n",
        "                relevant_text = extract_relevant_resume_sections(raw_text)\n",
        "                resumes.append((file, relevant_text))\n",
        "                ################################extra\n",
        "                print(\"Resume text\")\n",
        "                print(relevant_text)\n",
        "    print(resumes)\n",
        "    return resumes\n",
        "\n",
        "# Function to load and preprocess job description\n",
        "def load_job_description(file_path):\n",
        "    \"\"\"\n",
        "    Load a job description from a text file, extract relevant sections, preprocess, and return the text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            raw_text = f.read()\n",
        "            relevant_text = extract_relevant_job_description_sections(raw_text)\n",
        "            print(\"Job decription text\")\n",
        "            ################################extra\n",
        "            print(relevant_text)\n",
        "            return relevant_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading job description {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main processing function\n",
        "def match_resumes_to_job_description(resume_folder, job_description_file, output_excel):\n",
        "    \"\"\"\n",
        "    Match resumes to the job description, calculate similarity scores, and save results to Excel.\n",
        "    \"\"\"\n",
        "    # Load the model\n",
        "    model = SentenceTransformer('bwbayu/sbert_model_jobcv') #pretrained bert for cv\n",
        "    # model = SentenceTransformer('all-MiniLM-L6-v2') #good\n",
        "    # model = SentenceTransformer('paraphrase-MiniLM-L6-v2') bad\n",
        "    #model = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "\n",
        "\n",
        "\n",
        "    # Load and preprocess resumes\n",
        "    resumes = load_resumes(resume_folder)\n",
        "    if not resumes:\n",
        "        print(\"No valid resumes found in the folder.\")\n",
        "        return\n",
        "\n",
        "    # Load and preprocess job description\n",
        "    job_description = load_job_description(job_description_file)\n",
        "    if not job_description:\n",
        "        print(\"Job description file could not be processed.\")\n",
        "        return\n",
        "\n",
        "    # Encode the job description\n",
        "    job_embedding = model.encode([job_description])[0]\n",
        "\n",
        "    # Process each resume and calculate similarity\n",
        "    results = []\n",
        "    for filename, resume_text in resumes:\n",
        "        resume_embedding = model.encode([resume_text])[0]\n",
        "        similarity_score = cosine_similarity([job_embedding], [resume_embedding])[0][0]\n",
        "        results.append((filename, similarity_score))\n",
        "\n",
        "    # Sort results by similarity score in descending order\n",
        "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Save results to an Excel file\n",
        "    results_df = pd.DataFrame(results, columns=[\"Resume Filename\", \"Similarity Score\"])\n",
        "    results_df.to_excel(output_excel, index=False, engine='openpyxl')\n",
        "    print(f\"Results saved to {output_excel}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unjX6IxBXyO0",
        "outputId": "224caca1-6e40-41ab-f1d4-7cbf9dac13a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resume text\n",
            "work experience graphic designer brightcreations agency los angeles ca designed visual assets for social media campaigns and client presentations collaborated with the marketing team to develop branding strategies for clients marketing intern brandfocus san diego ca assisted in running social media campaigns on facebook and instagram created promotional materials using canva and indesign education bachelor s in graphic design california college of the arts com objective creative professional with a passion for design looking for opportunities in graphic design or branding skills adobe photoshop illustrator and after effects basic knowledge of wordpress and seo principles excellent eye for detail and strong communication\n",
            "Resume text\n",
            "looking to grow in the field of analytics and data science skills python pandas matplotlib sql some r basic machine learning logistic regression decision trees familiar with tableau excel pivottables work experience data analyst dataworks inc chicago il used python to clean and analyze sales data identifying a increase in high value customers created tableau dashboards for quarterly presentations to executives junior data analyst internship analyticsnow austin tx assisted in building a regression model for predicting customer churn maintained sql databases and ran ad hoc queries for team leads education bachelor s in computer science midwest state university\n",
            "Resume text\n",
            "with aws s sagemaker work experience senior data scientist abc corp new york ny present developed and deployed machine learning models to optimize supply chain operations reducing operational costs by built interactive dashboards with tableau to track kpis for the sales team conducted statistical analysis to identify customer behavior trends data analyst xyz analytics san francisco ca designed data pipelines to integrate diverse datasets improving processing time by collaborated with stakeholders to build predictive models for marketing roi education master s in data science university of analytics bachelor s in computer science tech institute\n",
            "[('poor.pdf', 'work experience graphic designer brightcreations agency los angeles ca designed visual assets for social media campaigns and client presentations collaborated with the marketing team to develop branding strategies for clients marketing intern brandfocus san diego ca assisted in running social media campaigns on facebook and instagram created promotional materials using canva and indesign education bachelor s in graphic design california college of the arts com objective creative professional with a passion for design looking for opportunities in graphic design or branding skills adobe photoshop illustrator and after effects basic knowledge of wordpress and seo principles excellent eye for detail and strong communication'), ('moderate.pdf', 'looking to grow in the field of analytics and data science skills python pandas matplotlib sql some r basic machine learning logistic regression decision trees familiar with tableau excel pivottables work experience data analyst dataworks inc chicago il used python to clean and analyze sales data identifying a increase in high value customers created tableau dashboards for quarterly presentations to executives junior data analyst internship analyticsnow austin tx assisted in building a regression model for predicting customer churn maintained sql databases and ran ad hoc queries for team leads education bachelor s in computer science midwest state university'), ('perfect.pdf', 'with aws s sagemaker work experience senior data scientist abc corp new york ny present developed and deployed machine learning models to optimize supply chain operations reducing operational costs by built interactive dashboards with tableau to track kpis for the sales team conducted statistical analysis to identify customer behavior trends data analyst xyz analytics san francisco ca designed data pipelines to integrate diverse datasets improving processing time by collaborated with stakeholders to build predictive models for marketing roi education master s in data science university of analytics bachelor s in computer science tech institute')]\n",
            "reading\n",
            "Job decription text\n",
            "Data Science\n",
            "We are seeking a passionate and experienced Data Scientist to join our team. The ideal candidate will have a strong background in data analysis, machine learning, and programming. You will work on analyzing large datasets, building predictive models, and collaborating with cross-functional teams to drive data-driven decision-making.\n",
            "\n",
            "Responsibilities:\n",
            "Analyze large datasets to derive insights and inform decision-making.\n",
            "Build and deploy machine learning models.\n",
            "Collaborate with stakeholders to identify business opportunities.\n",
            "Develop data pipelines and ensure data quality.\n",
            "Requirements:\n",
            "Proficiency in Python, R, or SQL.\n",
            "Experience with machine learning libraries like scikit-learn, TensorFlow, or PyTorch.\n",
            "Strong understanding of data visualization tools like Tableau or Power BI.\n",
            "Knowledge of statistics and predictive modeling.\n",
            "Bachelor's or Master's in Data Science, Computer Science, or a related field.\n",
            "Preferred Skills:\n",
            "Experience with big data tools like Spark or Hadoop.\n",
            "Familiarity with cloud platforms (AWS, Azure, GCP).\n",
            "Results saved to /content/test.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Example usage in Google Colab\n",
        "if __name__ == \"__main__\":\n",
        "    # Define paths\n",
        "    resume_folder = \"/content/resumes\"  # Path to the folder containing PDF resumes\n",
        "    job_description_file = \"/content/JD.txt\"  # Path to the job description file\n",
        "    #output_excel = \"/content/similarity_results.xlsx\"  # Path to save the results\n",
        "    output_excel = \"/content/test.xlsx\" #test #########################extra\n",
        "\n",
        "    # Ensure directories/files exist\n",
        "    if not os.path.exists(resume_folder):\n",
        "        print(f\"Resume folder not found: {resume_folder}\")\n",
        "    elif not os.path.exists(job_description_file):\n",
        "        print(f\"Job description file not found: {job_description_file}\")\n",
        "    else:\n",
        "        # Run the matching process\n",
        "        match_resumes_to_job_description(resume_folder, job_description_file, output_excel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRCPg6xXjhn7"
      },
      "source": [
        "# END\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P1lxaI8krwQ"
      },
      "source": [
        "# Resume Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l7N1_HeXo83h",
        "outputId": "e6b44578-483a-4dbd-8855-08084c07541a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyresparser\n",
            "  Downloading pyresparser-1.0.6-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (24.2.0)\n",
            "Requirement already satisfied: blis>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.7.11)\n",
            "Requirement already satisfied: certifi>=2019.6.16 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2024.8.30)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (5.2.0)\n",
            "Requirement already satisfied: cymem>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.0.8)\n",
            "Collecting docx2txt>=0.7 (from pyresparser)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.10)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.23.0)\n",
            "Requirement already satisfied: nltk>=3.4.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.2.2)\n",
            "Collecting pdfminer.six>=20181108 (from pyresparser)\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: preshed>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.0.9)\n",
            "Collecting pycryptodome>=3.8.2 (from pyresparser)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyrsistent>=0.15.2 (from pyresparser)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2019.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2024.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.32.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.16.0)\n",
            "Collecting sortedcontainers>=2.1.0 (from pyresparser)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: spacy>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.3.9)\n",
            "Requirement already satisfied: srsly>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.0.7)\n",
            "Requirement already satisfied: thinc>=7.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (7.4.6)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.66.6)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.2.3)\n",
            "Requirement already satisfied: wasabi>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.10.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.21.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (2024.9.11)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->pyresparser) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (43.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from preshed>=2.0.1->pyresparser) (1.0.10)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (75.1.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (1.1.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (2.22)\n",
            "Downloading pyresparser-1.0.6-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=f5ce1f50eebe36bb0d5c8b0b7b5b2f2cb7fbb27d55f49d9d5ebd16065555db82\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: sortedcontainers, docx2txt, pyrsistent, pycryptodome, pdfminer.six, pyresparser\n",
            "Successfully installed docx2txt-0.8 pdfminer.six-20240706 pycryptodome-3.21.0 pyresparser-1.0.6 pyrsistent-0.20.0 sortedcontainers-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyresparser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S82P59Cvuz_e",
        "outputId": "80bbd370-deaf-4fbb-a5cb-32774dce7080"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error parsing AshadAbdullah Resume - K213296 Ashad Abdullah Qureshi.pdf: 'PDFObjRef' object is not iterable\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to final_results.csv\n",
            "Extracted data saved to extracted_data.xlsx\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress specific warnings from SpaCy\n",
        "warnings.filterwarnings(\"ignore\", message=r\"\\[W031\\] Model '.*' requires spaCy v.*\", category=UserWarning)\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pyresparser import ResumeParser\n",
        "from multiprocessing import cpu_count, Pool\n",
        "from pyresparser.utils import extract_skills\n",
        "import spacy\n",
        "\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text = \" \".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Function to extract relevant sections from resumes\n",
        "def extract_relevant_resume_sections(text):\n",
        "    sections = {\"skills\": \"\", \"experience\": \"\", \"education\": \"\", \"projects\": \"\"}\n",
        "    skills_match = re.search(r'(skills|technical skills|core competencies|areas of expertise)(.*?)(experience|education|projects|summary|$)', text, re.DOTALL)\n",
        "    if skills_match:\n",
        "        sections[\"skills\"] = skills_match.group(2).strip()\n",
        "    experience_match = re.search(r'(experience|work history|employment history|professional experience|career summary)(.*?)(education|skills|projects|summary|$)', text, re.DOTALL)\n",
        "    if experience_match:\n",
        "        sections[\"experience\"] = experience_match.group(2).strip()\n",
        "    education_match = re.search(r'(education|academic background|qualifications|academic qualifications)(.*?)(experience|skills|projects|summary|$)', text, re.DOTALL)\n",
        "    if education_match:\n",
        "        sections[\"education\"] = education_match.group(2).strip()\n",
        "    projects_match = re.search(r'(projects|portfolio|notable work|key projects|case studies)(.*?)(experience|skills|education|summary|$)', text, re.DOTALL)\n",
        "    if projects_match:\n",
        "        sections[\"projects\"] = projects_match.group(2).strip()\n",
        "    combined_text = \" \".join([sections[\"skills\"], sections[\"experience\"], sections[\"education\"], sections[\"projects\"]])\n",
        "    return preprocess_text(combined_text)\n",
        "\n",
        "\n",
        "# Function to extract relevant sections from a job description\n",
        "def extract_relevant_job_description_sections(text):\n",
        "    responsibilities_match = re.search(r'(responsibilities|duties|role|tasks|job duties|job responsibilities)(.*?)(requirements|qualifications|skills|summary|desired skills|$)', text, re.DOTALL)\n",
        "    responsibilities = responsibilities_match.group(2).strip() if responsibilities_match else \"\"\n",
        "    requirements_match = re.search(r'(requirements|qualifications|skills|desired skills|eligibility criteria|job requirements)(.*?)(responsibilities|duties|summary|$)', text, re.DOTALL)\n",
        "    requirements = requirements_match.group(2).strip() if requirements_match else \"\"\n",
        "    skills_match = re.search(r'(skills|technical skills|core competencies|key qualifications|knowledge and abilities)(.*?)(responsibilities|requirements|summary|$)', text, re.DOTALL)\n",
        "    skills = skills_match.group(2).strip() if skills_match else \"\"\n",
        "    combined_text = \" \".join([responsibilities, requirements, skills])\n",
        "    return preprocess_text(combined_text)\n",
        "\n",
        "\n",
        "# Function to load and preprocess resumes\n",
        "def load_resumes(folder_path):\n",
        "    resumes = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".pdf\"):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            raw_text = extract_text_from_pdf(file_path)\n",
        "            if raw_text:\n",
        "                relevant_text = extract_relevant_resume_sections(raw_text)\n",
        "                resumes.append((file, relevant_text))\n",
        "    return resumes\n",
        "\n",
        "\n",
        "# Function to load and preprocess job description\n",
        "def load_job_description(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            raw_text = f.read()\n",
        "            relevant_text = extract_relevant_job_description_sections(raw_text)\n",
        "            return relevant_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading job description {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Skill score calculation functions\n",
        "def get_candidate_score(job_skill_count, job_skills, candidate_skills):\n",
        "    common_skills = job_skills.intersection(candidate_skills)\n",
        "    candidate_score = float(len(common_skills)) / job_skill_count\n",
        "    return candidate_score * 100\n",
        "\n",
        "\n",
        "def get_candidate_score_wrapper(args):\n",
        "    return get_candidate_score(*args)\n",
        "\n",
        "\n",
        "def sort_candidates(job_desc_text, candidates_df):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(job_desc_text)\n",
        "    job_skills = set([skill.lower() for skill in extract_skills(doc, doc.noun_chunks)])\n",
        "    job_skill_count = len(job_skills)\n",
        "    candidates_skills = [\n",
        "        set([skill.strip().lower() for skill in skill_list.split(\",\")])\n",
        "        for skill_list in candidates_df[\"Skills\"].values.tolist()\n",
        "    ]\n",
        "    processing_data = [(job_skill_count, job_skills, person_skills) for person_skills in candidates_skills]\n",
        "    with Pool(cpu_count()) as process_pool:\n",
        "        candidates_df[\"Score\"] = process_pool.map(get_candidate_score_wrapper, processing_data)\n",
        "    return candidates_df\n",
        "\n",
        "\n",
        "# Main function to process resumes and combine results\n",
        "def process_resumes(resume_folder, job_description_file, output_csv, output_excel):\n",
        "    # Load the model\n",
        "    bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Load and preprocess job description\n",
        "    job_description = load_job_description(job_description_file)\n",
        "    if not job_description:\n",
        "        print(\"Job description file could not be processed.\")\n",
        "        return\n",
        "\n",
        "    # Load and preprocess resumes\n",
        "    resumes = load_resumes(resume_folder)\n",
        "    if not resumes:\n",
        "        print(\"No valid resumes found in the folder.\")\n",
        "        return\n",
        "\n",
        "    # Encode the job description\n",
        "    job_embedding = bert_model.encode([job_description])[0]\n",
        "\n",
        "    # Process each resume and calculate scores\n",
        "    results = []\n",
        "    extracted_data = []\n",
        "    for filename, resume_text in resumes:\n",
        "        resume_embedding = bert_model.encode([resume_text])[0]\n",
        "        similarity_score = cosine_similarity([job_embedding], [resume_embedding])[0][0]\n",
        "\n",
        "        # Extract skills using pyresparser with error handling\n",
        "        try:\n",
        "            resume_data = ResumeParser(os.path.join(resume_folder, filename)).get_extracted_data()\n",
        "            candidate_skills = \", \".join(resume_data.get(\"skills\", []))\n",
        "            extracted_data.append({\n",
        "                \"Filename\": filename,\n",
        "                **resume_data\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing {filename}: {e}\")\n",
        "            candidate_skills = \"\"\n",
        "\n",
        "        candidates_df = pd.DataFrame({\"Skills\": [candidate_skills]})\n",
        "        ranked_df = sort_candidates(job_description, candidates_df)\n",
        "\n",
        "        # Get skill score and normalize\n",
        "        skill_score = ranked_df.iloc[0][\"Score\"] / 100\n",
        "\n",
        "        # Calculate final score\n",
        "        final_score = 0.7 * similarity_score + 0.3 * skill_score\n",
        "        results.append({\n",
        "            \"Resume Filename\": filename,\n",
        "            \"BERT Similarity\": similarity_score,\n",
        "            \"Skill Score\": skill_score,\n",
        "            \"Final Score\": final_score\n",
        "        })\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df = results_df.sort_values(by=\"Final Score\", ascending=False)  # Sort by Final Score in descending order\n",
        "    results_df.to_csv(output_csv, index=False)\n",
        "    print(f\"Results saved to {output_csv}\")\n",
        "\n",
        "    # Save extracted data to Excel\n",
        "    extracted_data_df = pd.DataFrame(extracted_data)\n",
        "    extracted_data_df.to_excel(output_excel, index=False)\n",
        "    print(f\"Extracted data saved to {output_excel}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == '__main__':\n",
        "    process_resumes(\"/content/resumes\", \"/content/job_description.txt\", \"final_results.csv\", \"extracted_data.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvCqEjyPDByI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}